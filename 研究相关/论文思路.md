写作顺序
1. Method
2. Experiment
3. Related work
4. Introdcution
5. Conclusion
6. Abstract

- # introduction
	- ## 脑肿瘤的背景
	- ## 脑肿瘤分割的背景
	- ## 信息融合
	- ## Proposed 特点
	- ## 贡献

---
## Loss

加权交叉熵损失（Weighted Cross-Entropy Loss）与Dice损失的混合损失函数。该损失函数旨在兼顾类别不平衡问题与分割区域的重叠度优化，从而提升模型在医学图像分割中的表现。整体损失函数定义如下：

$$ \mathcal{L}_{\text{total}} = 0.5 \cdot \mathcal{L}_{\text{CE}} + 0.5 \cdot (1 - \text{Dice}) $$


## EMF
受[参考文献]中提出的[模块名称]在二维图像融合方面的有效性启发，我们将此设计扩展为专为体积医学图像全三维版本。我们重新设计了核心Soblel，拉普拉斯和卷积操作，以处理三维输入，同时保留了原始模块的优势，以有效融合不同MRI图像。

我们设计了一种模态引导的成对融合机制，其中 T1C 模态作为主要参考，并通过专用的 EMF 分支与其他 MRI 模态单独融合。这实现了结构化和有针对性的特征集成，从而提高了跨序列互补信息的利用率。

---
修改：
受 DIVFusion 中 GRM 模块在二维图像融合中表现的启发（引用），我们提出了适用于三维医学图像的 EMF模块。该模块重新设计了核心的 Sobel、Laplacian 和卷积操作，使其适用于三维体素数据，并有效保留了几何感知能力如图所示。

基于该设计，我们进一步提出一种模态引导的成对融合策略，以 T1C 作为主模态，分别与其他三个模态配对，通过专用的 EMF 分支建模模态间的结构互补关系。融合后的特征通过 $1\times1\times1$ 卷积整合，为后续的分割提供统一的表示。

受到convolutional block attention module（CBAM）\cite{Woo_2018_ECCV}的在通道和空间两个维度计算注意力启发，在U-shape的bottleneck中我们增加了一个带有两层卷积和残差结构的ResCBAM。

To enhance the robustness and semantic capacity of the attention mechanism, we adopt a two-layer convolutional residual structure before applying channel and spatial attention. This design allows the attention branches to operate on deeper features with better semantic abstraction, which is especially beneficial for 3D medical images with high structural complexity and modality-specific variance.

----
我们提出的方法是一个融合和信息提取增强的两阶段方法。整体的workflow 如Fig2所示。 我们的架构延续了U-shape的形式，与Unet\cite{}相似,但是在网络的编码器之初，我们设计了模态边缘信息互补融合Stage，将T1c和其他模态信息整合，融合后输入到网络。然后在模型的bottleneck插入ResCBAM，帮助模型提取更胜层语义信息。

---
这些基于深度学习的脑肿瘤分割方法，最为常见的还是面向语义信息的卷积神经网络（CNNs)，并在之上进行改进。例如使用3D UNet\cite{agrawal2022segmentation}对脑肿瘤进行分割和分类，为进一步提升模型的局部特征表达，AGResU-Net\cite{9046011}同引入了注意力机制和残差机制.随着深度学习的发展，ViT被认为能更好的捕捉图像的长距离关系，因此基于Transformer的UNETR\cite{}，TransBTS\cite{}和Swin UNETR\cite{}等方法也被应用到了脑肿瘤分割中。但这些方法都没用考虑到模态之间的区别和互补关系。

为了进一步提升模态的融合效果，部分研究注意到了不同模态对脑肿瘤分割的贡献不同,所以对模态的处理不能同一而论，并且提出了边缘信息对分割任务的重要性。zhu2023brain}和Zhang\cite{zhang2025edge}为提取边缘信息设计了单独的分支，使用T1c和FLAIR模态来引导对边缘信息的学习，并设计了特征融合模块旨在融合提取的语义特征和边缘特征。而Edge-UNet\cite{allah2023edge}将MRI图像的边缘提取后，编码器部分设计双分支将MRI信息和处理后的MRI同时输入网络。DDU-Net\cite{jiang2021novel}将annotation中的边缘进行了处理，作为新的学习目标，在解码器使用双分支同时学习边缘和分割区域。这些研究都提示了我们注意MRI的不同贡献和边缘的重要性，但没有充分理解不同模态的贡献，but they fall short in thoroughly quantifying and utilizing the specific contributions of each modality to different tumor subregions, leaving room for more targeted and adaptive fusion strategies.


---
# Related Work

## 多模态脑肿瘤分割

要完成脑肿瘤多区域的分割，医生会参考不同的MRI图像进行判断，深度学习模型同样如此。然而，模态之间的信息差异对实现有效融合带来重大挑战。为了弥补这一差距，，现在的方法可以大致分为两个类型：开发更好的特征提取架构，以及针对MRI和分割任务特点考虑的创新的特征融合方法。

第一类方法侧重于设计更好特征提取架构。如AGResU-Net\cite{9046011}对注意力和残差结构的同时引入，基于Transformer的方法\cite{hatamizadeh2022unetr,wang2021transbts,hatamizadeh2021swin}则是利用了Tranformer能捕捉全局上下文信息方面出色地表现。M2GCNet\cite{}则是使用了结合GCN和注意力机制的方法来帮助模型捕捉不同MRI的复杂关系。

第二类方法中，考虑到MRI的提供的肿瘤信息不同，Yang\cite{10822448}和Zhang\cite{zhang2022mmformer}为每个模态单独设置了编码器，然后设置特征融合模块，对每个编码器输出的特征进行灵活地融合，再传递到解码器中。而zhu2023brain}和Zhang\cite{zhang2025edge}则是注意到了T1c和FLAIR的特殊性，单独设计了边缘检测pipline来辅助模型进行脑肿瘤分割。


## 

要对不同MRI在基于深度学习的脑肿瘤分割模型中的贡献进行分析，了解MRI和脑肿瘤子区域，我们可以从已有的进行模态消融的实验中观察到线索\cite{}

首先是T1c在enhancing tumor的分割中的不可取代性，在这些研究中，单模态场景下只有T1c能有效分割出enhancing tumor的区域。而FLAIR和T2在whole tumor和tumor core上表现突出。T1在单模态输入时，虽然没有出色的分割表现，但可以看出其同样在分割whole tumor和tumor core区域时更为优秀。

在双模态作为输入时，可以观察到T1c与其他模态一起输入，模型的分割表现在三个脑肿瘤子区域的性能虽比不上四个模态完全输入时的性能，但总体的表现相较于没有使用T1c的结果趋势更接近于最优表现。

综上，我们认为T1c与其他三种模态成互补关系。