目标：
实现一个建议的word2vec，牺牲一点效率，但便于理解。

## 基于推理方法和神经网络

不需要一次性使用所有的语料库数据，就可以训练出一个学习好的神经网络来将文本向量化。

**什么是基于推理？**
- 从上下文推测目标位置会是什么单词。

神经网络使用`one-hot`的方法将单词转化为向量。

设词表是 {you:0, say:1, hello:2}

| 单词    | 单词ID | one-hot   |
| ----- | ---- | --------- |
| you   | 0    | [1, 0, 0] |
| say   | 1    | [0, 1, 0] |
| hello | 2    | [0, 0, 1] |

只要将单词转化为固定长度的向量，神经网络的输入层的神经元个数就可以固定下来。

## 简单的W2V神经网络

word2vec一词最初用来指程序或者工具，但是随着该词的流行，在某些语境下，也指神经网络的模型。正确地说，CBOW模型和 skip-gram模型是word2vec中使用的两个神经网络。本节我们将主要讨论CBOW模型。

### CBOW continuous bag-of-words
